version: '3.8'

services:
  vtuber:
    build:
      context: ./Open-LLM-VTuber
      dockerfile: Dockerfile
    ports:
      - "12393:12393"
    env_file:
      - ./Open-LLM-VTuber/.env
    volumes:
      - ./storage/models:/app/asr/models
      - ./storage/cache:/app/cache
      - ./Open-LLM-VTuber/conf.yaml:/app/conf.yaml
    depends_on:
      redis:
        condition: service_healthy
    tty: true
    stdin_open: true

  event-monitor:
    build:
      context: ./event-monitor
      dockerfile: Dockerfile
    env_file:
      - ./event-monitor/.env
    volumes:
      - ./shared:/app/shared
    depends_on:
      ollama:
        condition: service_healthy
      redis:
        condition: service_healthy

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30
  ollama:
    image: ollama/ollama:latest
    healthcheck:
      test: ["CMD-SHELL", "pgrep ollama || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    ports:
      - "11434:11434"
    volumes:
      - ./storage/models:/root/.ollama

volumes:
  redis_data: 
